{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDbJWoO1yO8e"
   },
   "source": [
    "# Image Classification with CNN - LeNet5 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzQxqD6HyO8i"
   },
   "source": [
    "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFyVotRvyO8j"
   },
   "source": [
    "We will first download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTHLyL1fyO8j",
    "outputId": "19e29ee8-1f18-447b-a6b2-9ae79effb408",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist #type: ignore\n",
    "\n",
    "(XTrain, yTrain), (XTest, yTest) = fashion_mnist.load_data()\n",
    "\n",
    "# # # If your computer is slow, try to use a subset of data, e.g.\n",
    "# XTrain = XTrain[:10000]\n",
    "# yTrain = yTrain[:10000]\n",
    "# XTest = XTest[:2000]\n",
    "# yTest = yTest[:2000]\n",
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8ShXIANyO8l"
   },
   "source": [
    "As you already know, this dataset contains 10 classes:\n",
    "* 0:\tT-shirt/top\n",
    "* 1:\tTrouser\n",
    "* 2:\tPullover\n",
    "* 3:\tDress\n",
    "* 4:\tCoat\n",
    "* 5:\tSandal\n",
    "* 6:\tShirt\n",
    "* 7:\tSneaker\n",
    "* 8:\tBag\n",
    "* 9:\tAnkle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BvNG0PbyO8l"
   },
   "source": [
    "You can have a look at some images if needed, even if you already know them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "lnjqgv-GyO8m",
    "outputId": "3666f0d8-de2c-4709-b746-b1cf0c459f53",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Explore the data, display some input images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "labelClass = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "idx = np.random.randint(XTrain.shape[0])\n",
    "\n",
    "plt.imshow(XTrain[idx], cmap = \"gray_r\")\n",
    "plt.title(labelClass[yTrain[idx]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdYH6XW1yO8n"
   },
   "source": [
    "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fjv8XMPByO8o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Make the data preparation\n",
    "from tensorflow.keras.utils import to_categorical #type: ignore\n",
    "\n",
    "yTrainCat = to_categorical(yTrain, num_classes = 10)\n",
    "yTestCat = to_categorical(yTest, num_classes = 10)\n",
    "\n",
    "XTrainNorm = XTrain / 255\n",
    "XTestNorm = XTest / 255\n",
    "\n",
    "XTrainNorm = XTrainNorm.reshape(60000, 28, 28, 1)\n",
    "XTestNorm = XTestNorm.reshape(10000, 28, 28, 1)\n",
    "\n",
    "XTrainNorm.shape #Should be (60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9LKzxR9yO8o"
   },
   "source": [
    "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
    "\n",
    "The architecture is the following:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GKyMFlL6yO8o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
      "                                                                 \n",
      " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
      "                                                                 \n",
      " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " C5 (Dense)                  (None, 120)               48120     \n",
      "                                                                 \n",
      " F6 (Dense)                  (None, 84)                10164     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build your model\n",
    "from tensorflow.keras.models import Sequential #type: ignore\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense #type: ignore\n",
    "\n",
    "\n",
    "def lenet5():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer C1\n",
    "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "    # Layer S2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
    "    # Layer C3\n",
    "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3,3), activation='relu'))\n",
    "    # Layer S4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
    "    # Before going into layer C5, we flatten our units\n",
    "    model.add(Flatten())\n",
    "    # Layer C5\n",
    "    model.add(Dense(units=120, activation = 'relu', name='C5'))\n",
    "    # Layer F6\n",
    "    model.add(Dense(units=84, activation = 'relu', name = 'F6'))\n",
    "    # Output layer\n",
    "    model.add(Dense(units=10, activation = 'softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = lenet5()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1qBEauqyO8p"
   },
   "source": [
    "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPL3aKnyyO8p",
    "outputId": "9157f4ba-7840-4080-ecf9-7826ebca3f94",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 4s 104ms/step - loss: 1.5950 - accuracy: 0.4772 - val_loss: 0.9212 - val_accuracy: 0.6608\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.7931 - accuracy: 0.7060 - val_loss: 0.7375 - val_accuracy: 0.7014\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.6581 - accuracy: 0.7546 - val_loss: 0.6385 - val_accuracy: 0.7664\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.5863 - accuracy: 0.7829 - val_loss: 0.5811 - val_accuracy: 0.7891\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.5416 - accuracy: 0.8015 - val_loss: 0.5517 - val_accuracy: 0.7913\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.5129 - accuracy: 0.8105 - val_loss: 0.5190 - val_accuracy: 0.8088\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.4851 - accuracy: 0.8235 - val_loss: 0.4983 - val_accuracy: 0.8180\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.4703 - accuracy: 0.8285 - val_loss: 0.4926 - val_accuracy: 0.8197\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 4s 120ms/step - loss: 0.4591 - accuracy: 0.8329 - val_loss: 0.4880 - val_accuracy: 0.8202\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 3s 115ms/step - loss: 0.4415 - accuracy: 0.8406 - val_loss: 0.4613 - val_accuracy: 0.8348\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.4306 - accuracy: 0.8443 - val_loss: 0.4529 - val_accuracy: 0.8351\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.4196 - accuracy: 0.8494 - val_loss: 0.4498 - val_accuracy: 0.8344\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.4172 - accuracy: 0.8479 - val_loss: 0.4380 - val_accuracy: 0.8435\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.4065 - accuracy: 0.8543 - val_loss: 0.4383 - val_accuracy: 0.8414\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.4025 - accuracy: 0.8547 - val_loss: 0.4423 - val_accuracy: 0.8380\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.3942 - accuracy: 0.8589 - val_loss: 0.4271 - val_accuracy: 0.8448\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.3883 - accuracy: 0.8621 - val_loss: 0.4133 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.3832 - accuracy: 0.8628 - val_loss: 0.4164 - val_accuracy: 0.8490\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.3786 - accuracy: 0.8645 - val_loss: 0.4097 - val_accuracy: 0.8522\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 3s 115ms/step - loss: 0.3718 - accuracy: 0.8660 - val_loss: 0.4027 - val_accuracy: 0.8519\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 3s 116ms/step - loss: 0.3670 - accuracy: 0.8677 - val_loss: 0.4083 - val_accuracy: 0.8534\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 3s 116ms/step - loss: 0.3649 - accuracy: 0.8678 - val_loss: 0.4110 - val_accuracy: 0.8510\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 3s 114ms/step - loss: 0.3665 - accuracy: 0.8667 - val_loss: 0.3948 - val_accuracy: 0.8591\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.3566 - accuracy: 0.8725 - val_loss: 0.3841 - val_accuracy: 0.8619\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.3499 - accuracy: 0.8735 - val_loss: 0.3879 - val_accuracy: 0.8606\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.3474 - accuracy: 0.8758 - val_loss: 0.3834 - val_accuracy: 0.8611\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.3442 - accuracy: 0.8764 - val_loss: 0.3763 - val_accuracy: 0.8631\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.3396 - accuracy: 0.8782 - val_loss: 0.3816 - val_accuracy: 0.8622\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.3400 - accuracy: 0.8763 - val_loss: 0.3779 - val_accuracy: 0.8640\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 3s 110ms/step - loss: 0.3367 - accuracy: 0.8779 - val_loss: 0.3847 - val_accuracy: 0.8599\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.3419 - accuracy: 0.8753 - val_loss: 0.3732 - val_accuracy: 0.8654\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 3s 108ms/step - loss: 0.3340 - accuracy: 0.8796 - val_loss: 0.3760 - val_accuracy: 0.8665\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.3295 - accuracy: 0.8802 - val_loss: 0.3769 - val_accuracy: 0.8638\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 3s 108ms/step - loss: 0.3270 - accuracy: 0.8812 - val_loss: 0.3693 - val_accuracy: 0.8695\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.3234 - accuracy: 0.8830 - val_loss: 0.3580 - val_accuracy: 0.8710\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.3202 - accuracy: 0.8835 - val_loss: 0.3631 - val_accuracy: 0.8678\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.3181 - accuracy: 0.8848 - val_loss: 0.3622 - val_accuracy: 0.8693\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 3s 111ms/step - loss: 0.3157 - accuracy: 0.8857 - val_loss: 0.3624 - val_accuracy: 0.8694\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 3s 108ms/step - loss: 0.3172 - accuracy: 0.8855 - val_loss: 0.3561 - val_accuracy: 0.8720\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.3113 - accuracy: 0.8874 - val_loss: 0.3744 - val_accuracy: 0.8657\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3173 - accuracy: 0.8831 - val_loss: 0.3689 - val_accuracy: 0.8681\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 4s 127ms/step - loss: 0.3084 - accuracy: 0.8881 - val_loss: 0.3598 - val_accuracy: 0.8712\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.3052 - accuracy: 0.8896 - val_loss: 0.3608 - val_accuracy: 0.8692\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.3025 - accuracy: 0.8900 - val_loss: 0.3475 - val_accuracy: 0.8740\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.2998 - accuracy: 0.8913 - val_loss: 0.3456 - val_accuracy: 0.8769\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 3s 116ms/step - loss: 0.2979 - accuracy: 0.8927 - val_loss: 0.3493 - val_accuracy: 0.8746\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 3s 116ms/step - loss: 0.3001 - accuracy: 0.8913 - val_loss: 0.3470 - val_accuracy: 0.8752\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.2966 - accuracy: 0.8923 - val_loss: 0.3443 - val_accuracy: 0.8770\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.2938 - accuracy: 0.8931 - val_loss: 0.3384 - val_accuracy: 0.8788\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.2911 - accuracy: 0.8951 - val_loss: 0.3378 - val_accuracy: 0.8783\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.2927 - accuracy: 0.8937 - val_loss: 0.3336 - val_accuracy: 0.8800\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.2864 - accuracy: 0.8959 - val_loss: 0.3379 - val_accuracy: 0.8785\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.2867 - accuracy: 0.8965 - val_loss: 0.3383 - val_accuracy: 0.8781\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.2847 - accuracy: 0.8972 - val_loss: 0.3328 - val_accuracy: 0.8805\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.2875 - accuracy: 0.8956 - val_loss: 0.3324 - val_accuracy: 0.8800\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.2797 - accuracy: 0.8981 - val_loss: 0.3308 - val_accuracy: 0.8804\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.2795 - accuracy: 0.8975 - val_loss: 0.3292 - val_accuracy: 0.8811\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.2825 - accuracy: 0.8969 - val_loss: 0.3297 - val_accuracy: 0.8817\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.2737 - accuracy: 0.9000 - val_loss: 0.3254 - val_accuracy: 0.8835\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.2751 - accuracy: 0.9004 - val_loss: 0.3264 - val_accuracy: 0.8815\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.2735 - accuracy: 0.9001 - val_loss: 0.3282 - val_accuracy: 0.8830\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.2702 - accuracy: 0.9014 - val_loss: 0.3221 - val_accuracy: 0.8846\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.2685 - accuracy: 0.9016 - val_loss: 0.3190 - val_accuracy: 0.8858\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.2651 - accuracy: 0.9025 - val_loss: 0.3218 - val_accuracy: 0.8829\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.2647 - accuracy: 0.9029 - val_loss: 0.3287 - val_accuracy: 0.8833\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.2650 - accuracy: 0.9030 - val_loss: 0.3232 - val_accuracy: 0.8839\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.2625 - accuracy: 0.9040 - val_loss: 0.3195 - val_accuracy: 0.8841\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.2629 - accuracy: 0.9032 - val_loss: 0.3191 - val_accuracy: 0.8849\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.2710 - accuracy: 0.9008 - val_loss: 0.3146 - val_accuracy: 0.8864\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 0.2591 - accuracy: 0.9054 - val_loss: 0.3177 - val_accuracy: 0.8844\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.2574 - accuracy: 0.9054 - val_loss: 0.3180 - val_accuracy: 0.8834\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 3s 108ms/step - loss: 0.2562 - accuracy: 0.9056 - val_loss: 0.3160 - val_accuracy: 0.8872\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.2541 - accuracy: 0.9073 - val_loss: 0.3150 - val_accuracy: 0.8864\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.2488 - accuracy: 0.9095 - val_loss: 0.3088 - val_accuracy: 0.8911\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.2491 - accuracy: 0.9091 - val_loss: 0.3148 - val_accuracy: 0.8916\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.2500 - accuracy: 0.9079 - val_loss: 0.3099 - val_accuracy: 0.8913\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.2496 - accuracy: 0.9096 - val_loss: 0.3181 - val_accuracy: 0.8876\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.2475 - accuracy: 0.9099 - val_loss: 0.3155 - val_accuracy: 0.8871\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.2468 - accuracy: 0.9102 - val_loss: 0.3084 - val_accuracy: 0.8904\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2438 - accuracy: 0.9108 - val_loss: 0.3126 - val_accuracy: 0.8895\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2456 - accuracy: 0.9095 - val_loss: 0.3073 - val_accuracy: 0.8918\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2441 - accuracy: 0.9108 - val_loss: 0.3112 - val_accuracy: 0.8878\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.2391 - accuracy: 0.9132 - val_loss: 0.3059 - val_accuracy: 0.8935\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 3s 96ms/step - loss: 0.2375 - accuracy: 0.9122 - val_loss: 0.3039 - val_accuracy: 0.8924\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.2367 - accuracy: 0.9124 - val_loss: 0.3095 - val_accuracy: 0.8902\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2369 - accuracy: 0.9120 - val_loss: 0.3051 - val_accuracy: 0.8923\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2391 - accuracy: 0.9114 - val_loss: 0.3113 - val_accuracy: 0.8897\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 3s 96ms/step - loss: 0.2362 - accuracy: 0.9137 - val_loss: 0.3023 - val_accuracy: 0.8925\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2339 - accuracy: 0.9135 - val_loss: 0.3139 - val_accuracy: 0.8890\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2318 - accuracy: 0.9152 - val_loss: 0.2990 - val_accuracy: 0.8955\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 3s 96ms/step - loss: 0.2324 - accuracy: 0.9142 - val_loss: 0.3026 - val_accuracy: 0.8936\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2297 - accuracy: 0.9162 - val_loss: 0.3040 - val_accuracy: 0.8913\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2290 - accuracy: 0.9169 - val_loss: 0.3020 - val_accuracy: 0.8944\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2299 - accuracy: 0.9151 - val_loss: 0.3022 - val_accuracy: 0.8931\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2307 - accuracy: 0.9150 - val_loss: 0.3309 - val_accuracy: 0.8857\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 3s 96ms/step - loss: 0.2293 - accuracy: 0.9153 - val_loss: 0.3015 - val_accuracy: 0.8921\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2232 - accuracy: 0.9183 - val_loss: 0.3040 - val_accuracy: 0.8925\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2209 - accuracy: 0.9193 - val_loss: 0.2966 - val_accuracy: 0.8952\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2254 - accuracy: 0.9174 - val_loss: 0.3136 - val_accuracy: 0.8925\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.2223 - accuracy: 0.9182 - val_loss: 0.2996 - val_accuracy: 0.8954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126bc537350>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Compile and fit your model\n",
    "import os\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping #type: ignore\n",
    "from tensorflow.keras.callbacks import TensorBoard #type: ignore\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define now our callbacks\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "\n",
    "# Finally fit the model\n",
    "model.fit(x=XTrainNorm, y=yTrainCat, validation_data=(XTestNorm, yTestCat), epochs=100, batch_size=2048, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf-SqjjOyO8q"
   },
   "source": [
    "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2FTj7TSyO8q"
   },
   "source": [
    "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPjJoMQZyO8q",
    "outputId": "208f6295-df11-4146-8eeb-e81f1c4322d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "accuracy on train with NN: 0.92405\n",
      "accuracy on test with NN: 0.8985\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 2048\n",
    "yPredTrain = to_categorical(model.predict(XTrainNorm).argmax(axis=1), num_classes=10)\n",
    "yPredTest = to_categorical(model.predict(XTestNorm).argmax(axis=1), num_classes=10)\n",
    "\n",
    "print('accuracy on train with NN:', accuracy_score(yPredTrain, yTrainCat))\n",
    "print('accuracy on test with NN:', accuracy_score(yPredTest, yTestCat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vulsgHiyO8q"
   },
   "source": [
    "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
    "\n",
    "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
    "* `horizontal_flip=True`\n",
    "\n",
    "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
    "\n",
    "Begin by creating an object `ImageDataGenerator` with this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:58:37.442182Z",
     "start_time": "2020-08-19T11:58:37.438397Z"
    },
    "id": "pas-fMSIyO8q"
   },
   "outputs": [],
   "source": [
    "# TODO: Instantiate an ImageDataGenerator object\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #type: ignore\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7nCnu9syO8r"
   },
   "source": [
    "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zt6wXa3IyO8r",
    "outputId": "aa6078bb-d14e-4c98-97d0-49cdec4785f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4804\\4217090608.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(XTrainNorm, yTrainCat, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 4s 123ms/step - loss: 0.1987 - accuracy: 0.9261 - val_loss: 0.2835 - val_accuracy: 0.9011\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 4s 119ms/step - loss: 0.1955 - accuracy: 0.9282 - val_loss: 0.2815 - val_accuracy: 0.9007\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 4s 133ms/step - loss: 0.1966 - accuracy: 0.9271 - val_loss: 0.2952 - val_accuracy: 0.8965\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 4s 132ms/step - loss: 0.1992 - accuracy: 0.9256 - val_loss: 0.2796 - val_accuracy: 0.8996\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 0.1984 - accuracy: 0.9273 - val_loss: 0.2813 - val_accuracy: 0.9016\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 4s 121ms/step - loss: 0.1941 - accuracy: 0.9287 - val_loss: 0.2865 - val_accuracy: 0.8967\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 4s 123ms/step - loss: 0.1941 - accuracy: 0.9289 - val_loss: 0.2863 - val_accuracy: 0.8985\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 4s 122ms/step - loss: 0.1910 - accuracy: 0.9301 - val_loss: 0.2860 - val_accuracy: 0.8992\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 0.1945 - accuracy: 0.9277 - val_loss: 0.2828 - val_accuracy: 0.9011\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 0.1915 - accuracy: 0.9297 - val_loss: 0.2806 - val_accuracy: 0.9023\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 3s 117ms/step - loss: 0.1916 - accuracy: 0.9300 - val_loss: 0.2863 - val_accuracy: 0.9003\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 3s 118ms/step - loss: 0.1902 - accuracy: 0.9299 - val_loss: 0.2889 - val_accuracy: 0.8986\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 3s 117ms/step - loss: 0.1919 - accuracy: 0.9296 - val_loss: 0.2836 - val_accuracy: 0.9012\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 3s 117ms/step - loss: 0.1922 - accuracy: 0.9294 - val_loss: 0.2918 - val_accuracy: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126eb4aa190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: train your model\n",
    "batch_size = 2048\n",
    "model.fit_generator(datagen.flow(XTrainNorm, yTrainCat, batch_size=batch_size),\n",
    "                    validation_data=(XTestNorm, yTestCat), callbacks=callbacks,\n",
    "                    steps_per_epoch=len(XTrainNorm) / batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuzFke8pyO8r"
   },
   "source": [
    "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsTm86tuyO8r",
    "outputId": "36b5c6a1-63b6-4a92-82ea-961422411014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "accuracy on train with NN: 0.9310666666666667\n",
      "accuracy on test with NN: 0.8989\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size=1024\n",
    "yPredTrain = to_categorical(model.predict(XTrainNorm).argmax(axis=1), num_classes=10)\n",
    "yPredTest = to_categorical(model.predict(XTestNorm).argmax(axis=1), num_classes=10)\n",
    "\n",
    "print('accuracy on train with NN:', accuracy_score(yPredTrain, yTrainCat))\n",
    "print('accuracy on test with NN:', accuracy_score(yPredTest, yTestCat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOzkdGf7yO8s"
   },
   "source": [
    "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "01-LeNet5-solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
